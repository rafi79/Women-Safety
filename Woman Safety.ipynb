{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import streamlit as st\nimport google.generativeai as genai\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport librosa\nimport os\nimport json\nfrom datetime import datetime\nimport logging\nimport tempfile\n\nclass ContentAnalyzer:\n    def __init__(self, api_key):\n        # Initialize Gemini\n        genai.configure(api_key=api_key)\n        self.model = genai.GenerativeModel(\n            model_name=\"gemini-1.5-flash\",\n            generation_config={\n                \"temperature\": 0.3,\n                \"top_p\": 0.95,\n                \"max_output_tokens\": 8192,\n            }\n        )\n        \n        # Setup logging and output directory\n        logging.basicConfig(level=logging.INFO)\n        self.logger = logging.getLogger(__name__)\n        self.output_dir = \"analysis_results\"\n        os.makedirs(self.output_dir, exist_ok=True)\n\n    def analyze_content(self, video_file, audio_file):\n        \"\"\"Analyze uploaded video and audio content\"\"\"\n        try:\n            results = {\n                \"timestamp\": datetime.now().isoformat(),\n                \"video_analysis\": None,\n                \"audio_analysis\": None\n            }\n\n            # Analyze video if provided\n            if video_file is not None:\n                self.logger.info(\"Analyzing video...\")\n                with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_video:\n                    tmp_video.write(video_file.read())\n                    video_analysis = self.analyze_video(tmp_video.name)\n                    results[\"video_analysis\"] = video_analysis\n                os.unlink(tmp_video.name)\n\n            # Analyze audio if provided\n            if audio_file is not None:\n                self.logger.info(\"Analyzing audio...\")\n                with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_audio:\n                    tmp_audio.write(audio_file.read())\n                    audio_analysis = self.analyze_audio(tmp_audio.name)\n                    results[\"audio_analysis\"] = audio_analysis\n                os.unlink(tmp_audio.name)\n\n            # Save results\n            self.save_results(results)\n            \n            return results\n\n        except Exception as e:\n            self.logger.error(f\"Error in analysis: {e}\")\n            return {\"error\": str(e)}\n\n    def analyze_video(self, video_path):\n        \"\"\"Analyze video file\"\"\"\n        try:\n            # Extract frames\n            frames = self.extract_frames(video_path)\n            \n            # Convert frames to PIL images\n            pil_frames = [Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) \n                         for frame in frames]\n\n            prompt = \"\"\"\n            Analyze these video frames for signs of harassment or concerning behavior.\n            Focus on:\n            1. Aggressive or threatening movements\n            2. Signs of distress or danger\n            3. Unsafe situations\n            4. Suspicious patterns\n\n            Based on training with Bengali content, provide a detailed assessment.\n            \"\"\"\n\n            chat = self.model.start_chat(history=[])\n            response = chat.send_message([prompt, *pil_frames[:10]])  # First 10 frames\n            return response.text\n\n        except Exception as e:\n            self.logger.error(f\"Error in video analysis: {e}\")\n            return None\n\n    def analyze_audio(self, audio_path):\n        \"\"\"Analyze audio file\"\"\"\n        try:\n            # Extract audio features\n            features = self.extract_audio_features(audio_path)\n\n            prompt = f\"\"\"\n            Analyze these audio characteristics for concerning content:\n            \n            Audio Features:\n            - Duration: {features['duration']:.2f} seconds\n            - Energy Level: {features['rms_energy']:.4f}\n            - Spectral Features: {features['spectral_centroid']:.2f}\n            - Voice Patterns: {features['zero_crossing_rate']:.4f}\n            \n            Based on training with Bengali audio content:\n            1. Identify any concerning speech patterns\n            2. Detect aggressive or threatening tones\n            3. Analyze emotional indicators\n            4. Note any suspicious audio elements\n            \"\"\"\n\n            chat = self.model.start_chat(history=[])\n            response = chat.send_message(prompt)\n            return response.text\n\n        except Exception as e:\n            self.logger.error(f\"Error in audio analysis: {e}\")\n            return None\n\n    def extract_frames(self, video_path, max_frames=10):\n        \"\"\"Extract frames from video file\"\"\"\n        frames = []\n        cap = cv2.VideoCapture(video_path)\n        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        interval = max(1, total_frames // max_frames)\n\n        for i in range(0, total_frames, interval):\n            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n            ret, frame = cap.read()\n            if ret:\n                frames.append(frame)\n            if len(frames) >= max_frames:\n                break\n\n        cap.release()\n        return frames\n\n    def extract_audio_features(self, audio_path):\n        \"\"\"Extract audio features\"\"\"\n        y, sr = librosa.load(audio_path)\n        \n        return {\n            'duration': float(len(y) / sr),\n            'rms_energy': float(librosa.feature.rms(y=y).mean()),\n            'spectral_centroid': float(librosa.feature.spectral_centroid(y=y).mean()),\n            'zero_crossing_rate': float(librosa.feature.zero_crossing_rate(y).mean())\n        }\n\n    def save_results(self, results):\n        \"\"\"Save analysis results\"\"\"\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        output_file = os.path.join(self.output_dir, f\"analysis_{timestamp}.json\")\n        \n        with open(output_file, 'w', encoding='utf-8') as f:\n            json.dump(results, f, ensure_ascii=False, indent=2)\n        \n        self.logger.info(f\"Results saved to {output_file}\")\n        return output_file\n\ndef main():\n    st.set_page_config(\n        page_title=\"Content Analysis System\",\n        page_icon=\"ðŸ“Š\",\n        layout=\"wide\"\n    )\n\n    st.title(\"Content Analysis System\")\n    st.write(\"Upload video or audio files to analyze for concerning content\")\n\n    # Initialize session state for results\n    if 'results' not in st.session_state:\n        st.session_state.results = None\n    if 'results_file' not in st.session_state:\n        st.session_state.results_file = None\n\n    # Sidebar for API key\n    with st.sidebar:\n        st.header(\"Configuration\")\n        api_key = st.text_input(\"Enter Gemini API Key\", type=\"password\")\n        \n        st.markdown(\"---\")\n        st.markdown(\"\"\"\n        ### Features\n        - Video content analysis\n        - Audio characteristics analysis\n        - Automatic result saving\n        - Download results\n        \"\"\")\n\n    # Main content area\n    col1, col2 = st.columns(2)\n\n    with col1:\n        st.subheader(\"Upload Files\")\n        video_file = st.file_uploader(\"Upload Video\", type=['mp4', 'avi', 'mov'])\n        audio_file = st.file_uploader(\"Upload Audio\", type=['wav', 'mp3'])\n\n        if st.button(\"Analyze Content\", disabled=not api_key or (not video_file and not audio_file)):\n            if api_key:\n                with st.spinner(\"Analyzing content...\"):\n                    analyzer = ContentAnalyzer(api_key=api_key)\n                    st.session_state.results = analyzer.analyze_content(video_file, audio_file)\n                    if \"error\" not in st.session_state.results:\n                        st.success(\"Analysis complete!\")\n                    else:\n                        st.error(f\"Analysis failed: {st.session_state.results['error']}\")\n            else:\n                st.warning(\"Please enter your Gemini API key\")\n\n    with col2:\n        st.subheader(\"Analysis Results\")\n        if st.session_state.results and \"error\" not in st.session_state.results:\n            # Display timestamp\n            st.text(f\"ðŸ•’ Analysis completed at: {st.session_state.results['timestamp']}\")\n            \n            # Display video analysis\n            if st.session_state.results[\"video_analysis\"]:\n                st.markdown(\"### ðŸŽ¥ Video Analysis\")\n                st.markdown(\"---\")\n                st.write(st.session_state.results[\"video_analysis\"])\n            \n            # Display audio analysis\n            if st.session_state.results[\"audio_analysis\"]:\n                st.markdown(\"### ðŸ”Š Audio Analysis\")\n                st.markdown(\"---\")\n                st.write(st.session_state.results[\"audio_analysis\"])\n            \n            # Download button\n            st.download_button(\n                label=\"Download Results (JSON)\",\n                data=json.dumps(st.session_state.results, indent=2),\n                file_name=f\"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\",\n                mime=\"application/json\"\n            )\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}